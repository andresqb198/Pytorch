{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f80c72c-79aa-4563-a096-62809e48efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a0a71-92b2-4f40-b567-427de4e6c85e",
   "metadata": {},
   "source": [
    "# Tensors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4620fe-9cc6-4a85-bba0-1529c3b1468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NUmber\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52f40b3-7425-481d-8c94-3528a7837777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b07f5e-b5d9-4c25-8d28-41e37cbdee11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 5., 6.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "t2 = torch.tensor([2,4.,5,6])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce44181-4273-4255-b9d3-35cf857f0d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6],\n",
       "        [7, 8],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix\n",
    "t3 = torch.tensor([[5,6],[7,8],[8,9]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a73707-c30e-4e08-9e0c-fb46e801f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 12, 13],\n",
       "         [13, 14, 15]],\n",
       "\n",
       "        [[15, 16, 17],\n",
       "         [17, 18, 19]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-dimensional array\n",
    "t4 = torch.tensor([\n",
    "    [[11,12,13],\n",
    "    [13,14,15]],\n",
    "    [\n",
    "        [15,16,17],\n",
    "        [17,18,19]\n",
    "    ]\n",
    "])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2880fb7c-fa2c-471a-adab-75719ce8ac87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8dba7c3-0a47-4fe2-96ec-17183491d908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcc7d83-62f2-49f5-b10c-05dba809e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0284f8-e72c-483a-84fa-96bb3abe6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db3780-41bd-4b32-8407-61bde23cff07",
   "metadata": {},
   "source": [
    "# Tensors Operations and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a71e6a16-9e07-44b7-9bdd-bd6eef1cba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create  tensors\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd99ff2-d6da-49ec-8393-71d06b539ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arithmetic Operations\n",
    "y = w*x+b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca98ea95-0da9-4492-b1ad-ddd4ccc8bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2334a4d7-c969-44b6-a71c-048abc3944bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#Display Gradients\n",
    "print('dy/dx:',x.grad)\n",
    "print('dy/dw:',w.grad)\n",
    "print('dy/db:',b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64add32-7a6d-477f-b7b9-9330f628a1de",
   "metadata": {},
   "source": [
    "# Interoperability with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e74357-f562-4acd-b5f4-2db50bc738e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,2],[3,4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eba10a8c-5e52-40bf-8a0c-1d739301091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c013a120-7064-4bd7-9061-34747cb388b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x. dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6d631a2-f3a6-44f8-a74c-f5bcd06e3378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert a torch tensor to a numpy array\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d9a63-0ae6-42fc-a643-f8f97392886a",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3cd42b8-417e-4145-a843-c8cbee15456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5be45e05-f89b-4a54-90ce-60c36142e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMput (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9e3bced-d0cc-4bd5-a18e-f858fc1c1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea63d55f-0d3f-4cd5-9c79-506bac1541f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0f4df-ab63-43bc-9135-e9c10bc7bab7",
   "metadata": {},
   "source": [
    "# Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087bb2bf-23e0-4907-b72d-cba182411f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6914, -2.3950, -0.9955],\n",
      "        [-0.2904,  1.5077,  0.7031]], requires_grad=True)\n",
      "tensor([-0.5334,  0.2467], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weigths and biases\n",
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b = torch.randn(2,requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f813405c-e45e-4432-bc1e-2f5c943d4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdc42f2f-fa15-4a6d-8d44-e4497e96f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-153.3353,  110.2957],\n",
      "        [-212.0919,  151.4950],\n",
      "        [-319.0551,  217.7944],\n",
      "        [ -69.8306,   61.4688],\n",
      "        [-252.4364,  174.1650]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00f990c8-1623-4256-8fec-3b13a394ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f4bfd-cbdb-4285-984c-0e4b78b4c099",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4888fb5-5f87-4123-9dc5-5de843661f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MSE Loss\n",
    "def mse(preds,targets):\n",
    "    diff = preds-targets\n",
    "    return torch.sum(diff*diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f4c7bc7-6a99-4598-be62-cc23b331ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47138.9844, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a881c8-aae8-4cef-b031-8fa7585fb5ae",
   "metadata": {},
   "source": [
    "## Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43701446-6786-4c95-9cb4-4e1fcbe70fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46a34839-8483-4ad1-a28e-e93296a404b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6914, -2.3950, -0.9955],\n",
      "        [-0.2904,  1.5077,  0.7031]], requires_grad=True)\n",
      "tensor([[-22791.0977, -27317.5117, -16288.9551],\n",
      "        [  4243.1909,   4970.7661,   2929.8745]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c492defb-a566-4f8e-b849-9860dfd67c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5334,  0.2467], requires_grad=True)\n",
      "tensor([-277.5499,   51.0438])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac4f8a7e-0490-42d3-bab5-8b300c70c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8331d5-697a-482f-8db0-33f609984897",
   "metadata": {},
   "source": [
    "# Adjust weights and biases using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f1579a1-b390-4956-a832-9ad7e91ad7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-153.3353,  110.2957],\n",
      "        [-212.0919,  151.4950],\n",
      "        [-319.0551,  217.7944],\n",
      "        [ -69.8306,   61.4688],\n",
      "        [-252.4364,  174.1650]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff4d223a-7870-465c-83e2-7d3917d38cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47138.9844, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the loss\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fbcd3e7-ae01-4961-ab70-46c0ca9342ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-22791.0977, -27317.5117, -16288.9551],\n",
      "        [  4243.1909,   4970.7661,   2929.8745]])\n",
      "tensor([-277.5499,   51.0438])\n"
     ]
    }
   ],
   "source": [
    "#Cumpute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a447e259-cb07-417c-9868-5fe16f9997ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad*1e-5\n",
    "    b -= b.grad*1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9490f06-ebd4-4acc-b33d-16b4d4b82d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9193, -2.1218, -0.8327],\n",
      "        [-0.3329,  1.4580,  0.6738]], requires_grad=True)\n",
      "tensor([-0.5307,  0.2462], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0c9edc4-31a3-4a5f-9942-df26799684c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32728.7598, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6faee7f5-21f3-4869-8ec6-d7e34efd97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 mepochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds,targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad*1e-5\n",
    "        b -= b.grad*1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9e81d14-7ffb-4ef1-89e7-c90aae2a5931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(865.3555, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aa0990a-e114-4c2c-9dbb-31dbf6832008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 70.2479,  68.8553],\n",
       "        [ 88.3262,  96.4696],\n",
       "        [ 83.7416, 144.8499],\n",
       "        [ 97.3568,  28.0036],\n",
       "        [ 67.9511, 117.1373]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07665764-e111-48c5-bfd3-8734317bdc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736aacb-b015-4ec8-8b98-9152f7acb27e",
   "metadata": {},
   "source": [
    "# Linear regression using Pytorch built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "054a5521-34ab-433b-a48a-5ad27850aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5555606e-c0d5-4e24-98c5-fc76695935b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "413c2df6-b9bf-441b-9407-100ace9a0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1189e-8c1c-4856-a85d-1740db4aa339",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef3b656b-caa9-4897-8e20-ebe8c707e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "852084a3-ec28-43de-bd4d-5c3c40a737ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define dataset\n",
    "train_ds = TensorDataset(inputs,targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1c241bc-b24f-4b9f-b7e3-27efb8c4efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84040c69-bd07-45b1-b2c5-f099137ff1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d8ba125-98f5-4025-8bc0-14bc45af1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [ 73.,  66.,  44.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 92.,  87.,  64.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [102., 120.],\n",
      "        [ 57.,  69.],\n",
      "        [ 21.,  38.],\n",
      "        [ 82., 100.]])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "874f7b45-618f-4fb5-ae66-04a1a2e5e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4970, -0.5742, -0.3320],\n",
      "        [ 0.5738, -0.2479, -0.5610]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1805, -0.1184], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fed8acee-f1c3-4dcd-9a85-370ffbfdc34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4970, -0.5742, -0.3320],\n",
       "         [ 0.5738, -0.2479, -0.5610]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1805, -0.1184], requires_grad=True)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19246e2a-14c8-402e-91d1-06e9bd42361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -88.8503,    1.0335],\n",
       "        [-116.8272,   -5.6262],\n",
       "        [-139.2612,  -15.9594],\n",
       "        [ -87.4906,   26.9898],\n",
       "        [-112.4786,  -23.5993],\n",
       "        [ -88.7731,    1.8553],\n",
       "        [-116.5850,   -5.9393],\n",
       "        [-140.0902,  -15.9466],\n",
       "        [ -87.5678,   26.1681],\n",
       "        [-112.3135,  -24.7341],\n",
       "        [ -88.6081,    0.7204],\n",
       "        [-116.7500,   -4.8045],\n",
       "        [-139.5034,  -15.6462],\n",
       "        [ -87.6557,   28.1247],\n",
       "        [-112.5557,  -24.4210]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9debfe-206b-4c57-9859-aa4a87620885",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a52c650a-246f-4bb2-a3ff-b11cb83997b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fecdb7f4-20ff-483d-bcbf-d4bb3630ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f57ff413-eac4-4e69-b8e1-ab9f870e5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24375.3223, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs),targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b7c1d11-b969-4d85-94e3-974f6838760b",
   "metadata": {},
   "source": [
    "#Documentation\n",
    "?F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c159e4f1-8ab4-41e5-9b28-d7affd16d81b",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e14d62cc-d6fe-4f7c-b589-1522ebed724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimizer\n",
    "opt = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0551676-eda4-451a-b235-a31477778539",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a16c42d-9663-489a-883d-9c388209568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, traind_dl):\n",
    "    \n",
    "    #Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        #Train with batches of data\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            #Step 1\n",
    "            pred = model(xb)\n",
    "            \n",
    "            #Step 2\n",
    "            loss = loss_fn(pred,yb)\n",
    "            \n",
    "            #Step 3\n",
    "            loss.backward()\n",
    "            \n",
    "            #Step 4\n",
    "            opt.step()\n",
    "            \n",
    "            #Step 5\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            #Print progress\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afee0fb4-e9f7-44f0-8cf4-dd9be47e7cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 257.0315\n",
      "Epoch [10/100], Loss: 226.2509\n",
      "Epoch [10/100], Loss: 1842.2223\n",
      "Epoch [20/100], Loss: 441.7071\n",
      "Epoch [20/100], Loss: 274.1724\n",
      "Epoch [20/100], Loss: 876.3385\n",
      "Epoch [30/100], Loss: 602.6742\n",
      "Epoch [30/100], Loss: 140.9723\n",
      "Epoch [30/100], Loss: 375.8791\n",
      "Epoch [40/100], Loss: 344.0898\n",
      "Epoch [40/100], Loss: 430.6446\n",
      "Epoch [40/100], Loss: 27.3027\n",
      "Epoch [50/100], Loss: 198.9988\n",
      "Epoch [50/100], Loss: 195.3437\n",
      "Epoch [50/100], Loss: 189.6536\n",
      "Epoch [60/100], Loss: 144.2538\n",
      "Epoch [60/100], Loss: 148.1112\n",
      "Epoch [60/100], Loss: 146.8737\n",
      "Epoch [70/100], Loss: 171.8497\n",
      "Epoch [70/100], Loss: 107.5531\n",
      "Epoch [70/100], Loss: 64.3929\n",
      "Epoch [80/100], Loss: 53.3205\n",
      "Epoch [80/100], Loss: 128.9695\n",
      "Epoch [80/100], Loss: 85.2114\n",
      "Epoch [90/100], Loss: 100.0471\n",
      "Epoch [90/100], Loss: 13.2762\n",
      "Epoch [90/100], Loss: 105.5511\n",
      "Epoch [100/100], Loss: 61.9103\n",
      "Epoch [100/100], Loss: 59.3533\n",
      "Epoch [100/100], Loss: 59.8153\n"
     ]
    }
   ],
   "source": [
    "fit(100,model,loss_fn,opt,train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9dc57aa-d17c-4cbe-8dd7-8d712ced543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.2553,  72.6562],\n",
       "        [ 80.7752,  96.1217],\n",
       "        [118.8062, 139.2556],\n",
       "        [ 28.1216,  50.3719],\n",
       "        [ 95.4590, 103.4271],\n",
       "        [ 57.1544,  71.7473],\n",
       "        [ 80.3330,  95.2829],\n",
       "        [118.9838, 139.4225],\n",
       "        [ 29.2225,  51.2808],\n",
       "        [ 96.1177, 103.4972],\n",
       "        [ 57.8131,  71.8174],\n",
       "        [ 79.6743,  95.2128],\n",
       "        [119.2484, 140.0944],\n",
       "        [ 27.4629,  50.3017],\n",
       "        [ 96.5600, 104.3360]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ff1d1c5-980b-494c-80a8-a71188abd4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed9986-901f-46fe-8e7e-a9344891aaff",
   "metadata": {},
   "source": [
    "# Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4fc2a49-e855-43c2-a3d1-a4d496128b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee276e36-b3a9-41fb-a136-f6f48aca5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download trainig dataset\n",
    "dataset =MNIST(root='./data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "367e0399-f5f8-4153-ab0c-c85aabb2bf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a004b46-c1c3-4f3b-9f29-6c6a013d9976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/',train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad77fc1a-4080-4c39-9c5f-617210499d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7FE2BA1AC400>, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f795b6e5-4488-4aa0-8758-0279bc08d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6d57647-3d56-4bbf-a52d-3e19a2d973db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label =dataset[0]\n",
    "plt.imshow(image,cmap='gray')\n",
    "print('Label: ',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a26aa41-8ba5-4396-bf21-38de81f5ce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label =dataset[10]\n",
    "plt.imshow(image,cmap='gray')\n",
    "print('Label: ',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49f92e75-4345-4bd7-9f59-d1a9e01ccef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc4673e1-d57d-477e-a4e8-7505069eb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST dataset (images and labels)\n",
    "dataset = MNIST(root='data/',\n",
    "               train=True,\n",
    "               transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af745112-6765-42bd-bccb-a5ae090e39f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b5f8a2d-e2e2-4634-9357-b039e04cbfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:,10:15,10:15])\n",
    "print(torch.max(img_tensor),torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90dbba9f-2fa0-489f-ac5d-43a835620bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the image by passing in the 28x28 matrix\n",
    "plt.imshow(img_tensor[0,10:15,10:15],cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f088c-7ea8-4233-a2e8-2dbd4cbd328a",
   "metadata": {},
   "source": [
    "## Trainig and Validation Datasets\n",
    "\n",
    "1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n",
    "2. **Validation set** - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n",
    "3. **Test set** - used to compare different models or approaches and report the model's final accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "252f2b26-3aaa-4191-a52a-b5792bdb603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that randomly picks a given fraction of the images for the validation set\n",
    "def split_indices(n, val_pct):\n",
    "    #Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "    #Create random permutation of 0 to n-1\n",
    "    idxs = np.random. permutation(n)\n",
    "    #Pick first n_val indices for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48c9a57b-684c-43ab-9c2a-629d9103d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60000\n",
    "val_pct = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13a962ae-e23f-4359-8aaf-5d196c2e55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset),val_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "665d316f-67fb-4492-b971-75cbd97678ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "Sample val indices  [46135 19698 46558 51112 19307 19496 34429 14519 24827 58282   863 46767\n",
      "  9804 47027  5654 27595 51590 38483 38567 32112]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indices),len(val_indices))\n",
    "print('Sample val indices ', val_indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74523ffb-0e07-43f5-b1ba-ae98b8fa7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1619051-8c33-4feb-af59-77891d88a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "#Training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset,\n",
    "                          batch_size,\n",
    "                          sampler=train_sampler\n",
    ")\n",
    "\n",
    "#Validation sampler and data loader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset,\n",
    "                       batch_size,\n",
    "                       sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86744b22-c4d0-4655-92eb-a08c52a87e6a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3451e83-2574-43fe-8302-1ba02fc0aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "#Logistic regression model\n",
    "model = nn.Linear(input_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7c996ca-6648-4865-895c-21f075ff4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0078,  0.0202, -0.0211,  ..., -0.0007,  0.0056,  0.0069],\n",
       "        [-0.0088,  0.0082, -0.0152,  ...,  0.0175, -0.0281, -0.0106],\n",
       "        [ 0.0009,  0.0346,  0.0336,  ...,  0.0198, -0.0269,  0.0027],\n",
       "        ...,\n",
       "        [-0.0172, -0.0042, -0.0271,  ...,  0.0057,  0.0181, -0.0122],\n",
       "        [ 0.0247, -0.0176,  0.0102,  ..., -0.0150, -0.0248, -0.0114],\n",
       "        [-0.0169, -0.0126,  0.0134,  ..., -0.0170,  0.0281,  0.0355]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "277138c5-cbb2-44f8-8bd1-b1a6f3fc0e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0164, -0.0073,  0.0196, -0.0151,  0.0331,  0.0156,  0.0027, -0.0059,\n",
       "        -0.0270, -0.0341], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cccf4be-4881-478e-97a2-05b9a086066a",
   "metadata": {},
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f4eb4be-d396-452f-92eb-4d003f142016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "\n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "621f30cd-f512-4552-9da6-eb6a3776f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0113,  0.0356,  0.0347,  ...,  0.0034, -0.0104, -0.0347],\n",
       "         [-0.0149,  0.0137,  0.0327,  ...,  0.0019, -0.0322,  0.0107],\n",
       "         [-0.0044,  0.0110, -0.0272,  ...,  0.0004,  0.0248, -0.0326],\n",
       "         ...,\n",
       "         [-0.0077,  0.0175, -0.0344,  ...,  0.0152, -0.0158, -0.0196],\n",
       "         [-0.0310, -0.0343,  0.0136,  ...,  0.0139, -0.0335, -0.0337],\n",
       "         [ 0.0308, -0.0249, -0.0099,  ..., -0.0122,  0.0183,  0.0157]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0108, -0.0165, -0.0001, -0.0249, -0.0115,  0.0007,  0.0163,  0.0070,\n",
       "          0.0076,  0.0156], requires_grad=True)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0732940d-a757-4d08-bd8e-c0da291c9da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs.shape:  torch.Size([100, 10])\n",
      "Sample outputs :\n",
      " tensor([[-0.0813,  0.0437, -0.1302, -0.1006,  0.0487, -0.3301, -0.5271, -0.1435,\n",
      "         -0.1237,  0.2461],\n",
      "        [-0.1234,  0.1262, -0.0606,  0.0581,  0.1388,  0.0967, -0.2095, -0.0312,\n",
      "          0.0772, -0.0250]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "print('Outputs.shape: ',outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e536e4e5-eef3-4d81-a28b-68b3b8bb9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b91ecce8-b622-40db-afd4-910d0e182e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.1009, 0.1143, 0.0961, 0.0990, 0.1149, 0.0787, 0.0646, 0.0948, 0.0967,\n",
      "         0.1400],\n",
      "        [0.0875, 0.1123, 0.0931, 0.1049, 0.1137, 0.1090, 0.0802, 0.0959, 0.1069,\n",
      "         0.0965]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Apply softmax for each output row\n",
    "probs = F.softmax(outputs,dim=1)\n",
    "\n",
    "#Look at sample probabilities\n",
    "print(\"Sample probabilities:\\n\",probs[:2].data)\n",
    "\n",
    "#Add up the probabilities of an output row\n",
    "print(\"Sum: \",torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f825e0d-68fa-4ca1-abc4-eb59d6c04e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 4, 1, 5, 8, 8, 8, 9, 4, 9, 8, 1, 9, 8, 1, 9, 1, 8, 1, 8, 0, 4, 4, 1,\n",
      "        1, 1, 1, 1, 1, 8, 8, 1, 8, 9, 5, 5, 9, 1, 7, 8, 5, 1, 2, 4, 8, 1, 8, 8,\n",
      "        0, 8, 1, 9, 8, 1, 8, 9, 1, 5, 1, 9, 8, 1, 1, 1, 1, 9, 1, 8, 5, 1, 1, 1,\n",
      "        1, 1, 5, 8, 5, 1, 4, 8, 9, 1, 1, 8, 5, 1, 1, 9, 8, 9, 5, 9, 9, 1, 8, 1,\n",
      "        9, 1, 2, 8])\n",
      "tensor([0.1400, 0.1137, 0.1421, 0.1352, 0.1336, 0.1222, 0.1245, 0.1324, 0.1513,\n",
      "        0.1332, 0.1295, 0.1282, 0.1403, 0.1393, 0.1310, 0.1338, 0.1839, 0.1223,\n",
      "        0.1208, 0.1465, 0.1202, 0.1366, 0.1407, 0.1473, 0.1211, 0.1180, 0.1255,\n",
      "        0.1420, 0.1317, 0.1227, 0.1284, 0.1818, 0.1604, 0.1362, 0.1263, 0.1228,\n",
      "        0.1223, 0.1189, 0.1290, 0.1437, 0.1333, 0.1187, 0.1150, 0.1363, 0.1336,\n",
      "        0.1375, 0.1301, 0.1355, 0.1305, 0.1292, 0.1318, 0.1289, 0.1540, 0.1435,\n",
      "        0.1399, 0.1187, 0.1394, 0.1206, 0.1342, 0.1288, 0.1293, 0.1526, 0.1286,\n",
      "        0.1335, 0.1346, 0.1248, 0.1226, 0.1546, 0.1229, 0.1560, 0.1574, 0.1481,\n",
      "        0.1406, 0.1602, 0.1322, 0.1276, 0.1161, 0.1242, 0.1246, 0.1583, 0.1283,\n",
      "        0.1512, 0.1426, 0.1294, 0.1203, 0.1413, 0.1395, 0.1594, 0.1449, 0.1266,\n",
      "        0.1380, 0.1542, 0.1362, 0.1367, 0.1554, 0.1200, 0.1181, 0.1277, 0.1312,\n",
      "        0.1429], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs,dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a9263d5-ed2a-4094-be99-121e38470cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 1, 7, 1, 5, 1, 6, 0, 4, 2, 9, 3, 9, 0, 6, 9, 7, 4, 1, 0, 0, 2, 4, 3,\n",
       "        9, 1, 6, 8, 3, 4, 6, 4, 8, 4, 1, 1, 2, 1, 2, 8, 2, 8, 8, 5, 2, 2, 6, 9,\n",
       "        0, 9, 1, 5, 7, 2, 7, 9, 3, 1, 1, 4, 2, 7, 4, 7, 6, 7, 1, 7, 1, 6, 0, 9,\n",
       "        2, 3, 1, 7, 2, 7, 4, 0, 0, 6, 6, 7, 1, 9, 2, 9, 7, 4, 8, 4, 5, 0, 0, 1,\n",
       "        9, 2, 8, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17470d78-f891-4861-813e-c25957136751",
   "metadata": {},
   "source": [
    "## Evaluation Metric and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bc7a794-346f-4225-95e4-e8c5ccfd92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    " def accuracy(pred,true):\n",
    "        return torch.sum(pred==true).item()/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3ef5d54-2ac0-41bf-9a00-64e5969167b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87d8884d-d24b-4bd2-b674-aec4c6cf3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b74d325-4412-4eb4-b556-e3bf1d8d60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2490, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Loss for current batch of data\n",
    "loss = loss_fn(outputs,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3819d-e351-4825-ad6c-939dbb9ecbe8",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ec4cfb8-4f7d-4803-bed2-ee6e1634c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0458f-5837-46b7-a734-72d7b0a6537d",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "284036bc-8c92-453a-9df2-fb20592c5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    #Calculate loss\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        #Compute gradients\n",
    "        loss.backward()\n",
    "        #Update parameters\n",
    "        opt.step()\n",
    "        #Reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        #Compute the metric\n",
    "        metric_result = metric(preds,yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89d3cf2a-edea-4bc9-b93f-eece6711cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_d1, metric=None):\n",
    "    with torch.no_grad():\n",
    "        #Pass each batch throuh the model\n",
    "        results = [loss_batch(model,loss_fn,xb,yb,metric=metric) \n",
    "                   for xb,yb in valid_d1]\n",
    "        #Separate losses, count and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        #Total size of the dataset\n",
    "        total = np.sum(nums)\n",
    "        #Avg. loss across batches\n",
    "        avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            #Avg. of metric across batches\n",
    "            avg_metric = np.sum(np.multiply(metrics,nums)) / total\n",
    "        return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d95abaa7-1bc3-4065-ae83-dc3e329b66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs,dim=1)\n",
    "    return torch.sum(preds==labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "97a2edde-6dd4-470b-8d87-448b833dadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2760, Accuracy:.0.1863\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model,loss_fn,val_loader,metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy:.{:.4f}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8fc3733-37d6-4a3e-b528-aebba121a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,model,loss_fn, opt,train_dl,valid_dl,metric=None):\n",
    "    for epoch in range(epochs):\n",
    "        #Training\n",
    "        for xb,yb in train_dl:\n",
    "            loss,_,_ = loss_batch(model,loss_fn,xb,yb,opt)\n",
    "        #Evaluation\n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        \n",
    "        #Print progress\n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                 .format(epoch+1,epochs,val_loss))\n",
    "        else:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'\n",
    "                 .format(epoch+1,epochs,val_loss,metric.__name__,val_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b2a350a-1aab-44b5-9f92-7687e13aa526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redifine model and optimizer\n",
    "model = MnistModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95bb3c80-2e8e-48e9-9fd6-c47989adad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.8889, accuracy: 0.6664\n",
      "Epoch [2/5], Loss: 1.5872, accuracy: 0.7498\n",
      "Epoch [3/5], Loss: 1.3756, accuracy: 0.7814\n",
      "Epoch [4/5], Loss: 1.2240, accuracy: 0.7984\n",
      "Epoch [5/5], Loss: 1.1118, accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "fit(5,model,F.cross_entropy,optimizer,train_loader,val_loader,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f3a0f-2f5a-4673-9765-6ce4a6f6d871",
   "metadata": {},
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f425cc1f-d390-4213-81d0-1c1e30130228",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d3cece7-47a1-46df-94fb-d75c319ae51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0265, -0.0053, -0.0292,  ...,  0.0125,  0.0084,  0.0084],\n",
       "                      [-0.0333,  0.0024, -0.0311,  ...,  0.0037,  0.0226,  0.0224],\n",
       "                      [-0.0230, -0.0313,  0.0059,  ...,  0.0340,  0.0221,  0.0242],\n",
       "                      ...,\n",
       "                      [-0.0294, -0.0064, -0.0147,  ..., -0.0290, -0.0250, -0.0018],\n",
       "                      [-0.0327,  0.0297,  0.0070,  ...,  0.0289, -0.0144,  0.0097],\n",
       "                      [ 0.0186, -0.0245, -0.0177,  ...,  0.0082, -0.0309, -0.0192]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0251,  0.0742, -0.0422,  0.0073, -0.0148,  0.0026, -0.0060, -0.0135,\n",
       "                      -0.0370, -0.0078]))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d28807c7-46ca-40ab-9335-383bda51899c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0265, -0.0053, -0.0292,  ...,  0.0125,  0.0084,  0.0084],\n",
       "                      [-0.0333,  0.0024, -0.0311,  ...,  0.0037,  0.0226,  0.0224],\n",
       "                      [-0.0230, -0.0313,  0.0059,  ...,  0.0340,  0.0221,  0.0242],\n",
       "                      ...,\n",
       "                      [-0.0294, -0.0064, -0.0147,  ..., -0.0290, -0.0250, -0.0018],\n",
       "                      [-0.0327,  0.0297,  0.0070,  ...,  0.0289, -0.0144,  0.0097],\n",
       "                      [ 0.0186, -0.0245, -0.0177,  ...,  0.0082, -0.0309, -0.0192]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0251,  0.0742, -0.0422,  0.0073, -0.0148,  0.0026, -0.0060, -0.0135,\n",
       "                      -0.0370, -0.0078]))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MnistModel()\n",
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6800bef-800e-4d11-916a-3fb9b35a41be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1118, Accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "test_loss, total, test_acc = evaluate(model2,loss_fn,val_loader,metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5e06f-7440-46a9-9fee-a55ccd07578c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
