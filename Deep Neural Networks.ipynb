{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66744478-3bd8-4ac4-bc76-70fb5cd309b4",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a38224-d27e-40e7-b961-04c88bf88fad",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b724ab3-e137-4478-8a78-112c168df95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "068772ff-3f34-4161-9700-0e2acb287e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='./data',\n",
    "               download=False,\n",
    "               transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1b1614-731e-4422-a03b-756ea7c5df62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7abddcedc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894ca205-6792-4450-9e4a-05489b3a63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that randomly picks a given fraction of the images for the validation set\n",
    "def split_indices(n, val_pct):\n",
    "    #Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "    #Create random permutation of 0 to n-1\n",
    "    idxs = np.random. permutation(n)\n",
    "    #Pick first n_val indices for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b954b1cd-57ad-4e5e-b59d-ec03f13813af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "Sample val indices  [24933 11995 21589 56375 13335 41421 44722 41682 36772 41604 30676 24773\n",
      "  9105 22967 19199 25438  2508 33804 39895 17861]\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset),val_pct=0.2)\n",
    "print(len(train_indices),len(val_indices))\n",
    "print('Sample val indices ', val_indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "320ab21e-c1ea-4c1d-b9ba-2cf331066abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "#Training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset,\n",
    "                          batch_size,\n",
    "                          sampler=train_sampler\n",
    ")\n",
    "\n",
    "#Validation sampler and data loader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(dataset,\n",
    "                       batch_size,\n",
    "                       sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11f961-5953-4129-b872-24583a53c0c7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9465221a-a226-409d-81a6-fdc8ba9de6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "#Logistic regression model\n",
    "model = nn.Linear(input_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d162bb5-0ff2-4efe-ad5c-3c13a77a3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f3184d-caab-42ee-8851-689827a3c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedfoward neuaral network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size,out_size):\n",
    "        super().__init__()\n",
    "        #hidden layer\n",
    "        self.linear1 = nn.Linear(in_size,hidden_size)\n",
    "        #output layer\n",
    "        self.linear2 = nn.Linear(hidden_size,out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        #Flatten the image tensors\n",
    "        xb = xb.view(xb.size(0),-1)\n",
    "        #Get the intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        #Apply the activation function\n",
    "        out = F.relu(out)\n",
    "        #Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ba2ce39-f958-4e8e-b9fd-e1109e67c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(input_size,hidden_size=32,\n",
    "                   out_size=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c18d4a-6bb5-4c8b-ac34-e6fbad488360",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06f8ea0a-7ccc-427c-981a-7d8f324d9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "037c7bc8-080f-4981-bcf2-168aa60bea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images.shape torch.Size([100, 1, 28, 28])\n",
      "Loss:  2.30692195892334\n",
      "Output.shape:  torch.Size([100, 10])\n",
      "Sample Outputs:\n",
      " tensor([[-0.2306,  0.1421,  0.1584, -0.2860, -0.1022, -0.1719, -0.0225, -0.2390,\n",
      "         -0.1212,  0.1950],\n",
      "        [-0.1900,  0.0724,  0.1927, -0.1816, -0.0510, -0.1439,  0.0377, -0.2474,\n",
      "         -0.0970,  0.1953]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('Images.shape',images.shape)\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs,labels)\n",
    "    print('Loss: ', loss.item())\n",
    "    break\n",
    "\n",
    "print('Output.shape: ', outputs.shape)\n",
    "print('Sample Outputs:\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad967433-eb11-40d0-b136-424cc8ba257f",
   "metadata": {},
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5517780-d19a-465b-aa84-24ecd7c6c94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "098279b7-6060-4f53-8d00-cb40b8a22a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecdb727b-a918-43e6-82b1-fe34fde57e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fcadf-5053-42be-a80d-0eb5a157d8fb",
   "metadata": {},
   "source": [
    "Function that can move data and model to a chosen device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cd3e333-b86a-43d1-bbe7-fd3f91d98acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6fca748-14f0-47dd-862e-b3f2e16cffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4]), tensor([1, 2, 3, 4])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_device([torch.tensor([1,2,3,4]),torch.tensor([1,2,3,4])],device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dd54d9e-7313-4c51-9a4d-6e03beb2cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95fce342-2335-42da-9c73-f05bff5cda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dataloader,device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to a device\"\"\"\n",
    "        for batch  in self.dataloader:\n",
    "            yield to_device(batch,self.device)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0eeadddd-4763-4f38-8d8a-703f1da11921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl,device)\n",
    "valid_dl = DeviceDataLoader(valid_dl,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f55e3543-ab5d-4cb7-9f23-23bc48e750f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device: cpu\n",
      "yb: tensor([3, 8, 8, 5, 8, 8, 3, 5, 9, 2, 5, 4, 4, 4, 7, 9, 1, 8, 8, 3, 4, 1, 4, 0,\n",
      "        3, 6, 1, 0, 3, 8, 1, 0, 8, 5, 5, 2, 1, 5, 7, 6, 1, 2, 1, 1, 1, 5, 2, 4,\n",
      "        9, 3, 7, 6, 1, 6, 7, 4, 4, 4, 2, 3, 2, 3, 9, 6, 1, 4, 1, 7, 3, 8, 6, 7,\n",
      "        7, 9, 2, 0, 4, 7, 3, 7, 4, 7, 1, 2, 1, 4, 1, 1, 2, 1, 7, 5, 7, 7, 4, 1,\n",
      "        5, 6, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in valid_dl:\n",
    "    print('xb.device:',xb.device)\n",
    "    print('yb:',yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f719f30-c3d1-462f-80d9-b2a4d4a1ff33",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6063eb3-bed3-4f8d-bfb6-c16a32f7c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    #Calculate loss\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        #Compute gradients\n",
    "        loss.backward()\n",
    "        #Update parameters\n",
    "        opt.step()\n",
    "        #Reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        #Compute the metric\n",
    "        metric_result = metric(preds,yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da8b8a53-bdfe-4100-a01a-e119d96ce0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        #Pass each batch throuh the model\n",
    "        \n",
    "        results = [loss_batch(model,loss_fn,xb,yb,metric=metric) for xb,yb in valid_dl]\n",
    "        #Separate losses, count and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        #Total size of the dataset\n",
    "        total = np.sum(nums)\n",
    "        #Avg. loss across batches\n",
    "        avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            #Avg. of metric across batches\n",
    "            avg_metric = np.sum(np.multiply(metrics,nums)) / total\n",
    "        return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a4f7231-58a2-460f-8ed4-c65adb9fde1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,lr,model,loss_fn,train_dl,\n",
    "        valid_dl,metric=None, opt_fn=None):\n",
    "    losses,metrics = [],[]\n",
    "    \n",
    "    #Instantiate the optimizer\n",
    "    if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "    opt = opt_fn(model.parameters(),lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #Training\n",
    "        for xb,yb in train_dl:\n",
    "            loss_batch(model,loss_fn,xb,yb,opt)\n",
    "            \n",
    "        #Evaluation\n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        \n",
    "        #Record the loss & metric\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "        \n",
    "        #Print progress\n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                 .format(epoch+1,epochs,val_loss))\n",
    "        else:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'\n",
    "                 .format(epoch+1,epochs,val_loss,metric.__name__,val_metric))\n",
    "    \n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f81c8c7a-cde5-4d57-93bd-ba93107089b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,labels):\n",
    "    _, preds =torch.max(outputs,dim=1)\n",
    "    return torch.sum(preds==labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "81732c29-31bc-4916-9614-630d1730fc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model on GPU\n",
    "model = MnistModel(input_size,hidden_size=32,out_size=num_classes)\n",
    "to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a0f30ab-776b-43ce-8106-d1362e66afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3155, Accuracy:.0.1057\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, F.cross_entropy,\n",
    "                                   valid_dl, metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy:.{:.4f}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da1a5d09-22de-4afb-a51d-932664cf128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1294, accuracy: 0.9611\n",
      "Epoch [2/5], Loss: 0.1237, accuracy: 0.9641\n",
      "Epoch [3/5], Loss: 0.1404, accuracy: 0.9599\n",
      "Epoch [4/5], Loss: 0.1454, accuracy: 0.9573\n",
      "Epoch [5/5], Loss: 0.1201, accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "losses1, metrics1 = fit(epochs=5,lr=0.5,model=model,loss_fn=F.cross_entropy,\n",
    "                        train_dl=train_dl,valid_dl=valid_dl,metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "683f42f5-53e0-43aa-a195-49e9b136425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1066, accuracy: 0.9686\n",
      "Epoch [2/5], Loss: 0.1070, accuracy: 0.9690\n",
      "Epoch [3/5], Loss: 0.1061, accuracy: 0.9694\n",
      "Epoch [4/5], Loss: 0.1068, accuracy: 0.9688\n",
      "Epoch [5/5], Loss: 0.1065, accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "losses2, metrics2 = fit(epochs=5,lr=0.1,model=model,loss_fn=F.cross_entropy,\n",
    "                        train_dl=train_dl,valid_dl=valid_dl,metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0d489dd1-dfa0-43b0-a9d7-b1f196a6ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "48c603ff-87da-4f63-aad8-63d737ad5849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs No of epochs')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjoUlEQVR4nO3deZxkdXnv8c+3l+nZ92abGZiFRUDZ7KBiVJBcATf0RqPgHpWQiGJioiSuMcm93myae0FHrgoubC6IRFFQo+NNBpVhEVlEpxqGaQbo6tm7Z+mlnvvHOd1T01TP1Mz06eqq832/XvXqs9U5z6nuPk/9lvM7igjMzCy/mmodgJmZ1ZYTgZlZzjkRmJnlnBOBmVnOORGYmeWcE4GZWc45EZjVKUnTJP27pK2SvlHreAAk/VTSu2odhx0YJwKrSvoPvllSW61jmcwkPSbpaUkzypa9S9JPMzjc64DDgQUR8foM9m854URg+yVpKfAiIIBXT/CxWybyeOOkBbh8Ao5zDPDbiBicgGNZA3MisGq8Ffg5cC3wtvIVkpZIullSUdJGSVeWrXu3pIclbZf0kKQz0uUh6diy7a6V9Pfp9NmSuiR9SNJTwDWS5kn6bnqMzen04rL3z5d0jaQN6fpb0uUPSHpV2XatknoknTb6BNM4X1k235Jue4akqZK+lp7fFkl3STp8H5/XPwF/KWlupZWSzkr3sTX9edZYO5J0Yloa2yLpQUmvTpf/LfAx4A2SeiW9s8J7myRdIamQxv51SfPTdUvT38Ml6ef2pKQPlL23TdJn0nUb0um2svUXSrpP0rZ0/+eXHfoYSf+V/t7vkLQwfc+Bfo42QZwIrBpvBa5LX+cN//NKaga+C6wDlgKLgBvTda8HPpG+dzZJSWJjlcc7AphP8o33EpK/02vS+aOBncCVZdt/FZgOnAwcBnw6Xf4V4M1l270ceDIi7qtwzBuAi8rmzwN6IuIekuQ3B1gCLAAuTWMYyxrgp8Bfjl6RXoi/B/zvdF//CnxP0oIK27YC/w7ckZ7Xe4HrJJ0QER8H/gdwU0TMjIgvVojjfcBrgJcARwGbgatGbXMOcBzwMuAKSX+QLv8w8HzgNOBU4EzgI2lcZ5J8tn8FzAVeDDxWts+LgXekMU8p+xwO9HO0iRIRfvk15gv4fWAAWJjO/wb483T6BUARaKnwvtuBy8fYZwDHls1fC/x9On020A9M3UdMpwGb0+kjgRIwr8J2RwHbgdnp/DeBD46xz2PTbaen89cBH0un/xhYDZxSxef1GPAHwLOBrUA78C7gp+n6twC/HPWeO4G3V9jXi4CngKayZTcAn0inPwF8bR+xPAycWzZ/ZPq7bCFJ3AE8q2z9PwJfTKcLwMvL1p0HPJZOfx749BjH/CnwkbL5PwN+cKCfo18T+3KJwPbnbcAdEdGTzl/PnuqhJcC6qFxHvYTkYnIwihGxa3hG0nRJn5e0TtI24GfA3LREsgTYFBGbR+8kIjYA/wX8YVpNcwHJBf4ZImItyYXzVZKmk5Rgrk9Xf5Uksd2YVpP8Y/ptfUwR8QBJaemKUauOIilBlVtHUpoa7ShgfUSUqti2kmOAb6fVMFtIzm+IpIF52PpR+z5qjDjL1+3vd/tU2fQOYGY6fcCfo00MJwIbk6RpwB8BL5H0VFpn/+fAqZJOJbmIHD1Gg+56YMUYu95BUpUz7IhR60cPifsB4ATgeRExm6QqAkDpceaPVR8PfJmkeuj1wJ0R8cQY28Ge6qELgYfS5EBEDETE30bEScBZwCtJqrz25+PAu9n7wr2B5AJd7migUlwbgCWSmqrYtpL1wAURMbfsNXXUZ7Bk1L43jBFn+bp9/W7HdAifo2XMicD25TUk3yBPIqmOOQ04Efh/JP/AvwSeBD4laUbaGPjC9L1fIGkwfa4Sx0oavrDcB1wsqTltZHzJfuKYRVKXvCWtY//48IqIeBL4PvDZtFG5VdKLy957C3AGSS+er+znODeS1JX/KXtKA0g6R9Jz0hLINpLqlaH97Gu4lHETSV39sNuA4yVdnDZIv4Hk8/1uhV38AugDPpie19nAq9I4q7ES+Ifhz11Su6QLR23z0bTEdTJJvf5N6fIbgI+k71lI0jD9tXTdF4F3SDo3bZBeJOlZ+wvmYD9Hy54Tge3L24BrIuLxiHhq+EXSUPsmkm/kryKpX38c6ALeABAR3wD+geSCup3kgjw/3e/l6fu2pPu5ZT9xfAaYBvSQ9F76waj1byG5qPwG6AbeP7wiInYC3wKWATfv6yBpUrmT5NvqTWWrjiBpX9hGUr2yij0Xxf35JDByT0FEbCT5JvwBksbzDwKvLKt6K4+nn6SK6gKSc/8s8NaI+E2Vx/434FbgDknbST67543aZhWwFvgx8M8RcUe6/O9JGr3vB34N3JMuIyJ+SZI0Pk3SDrKKZ5ZyKjmUz9EypAg/mMYam6SPAcdHxJv3u3FOKLk35FGgdYw2HsuRerxZx6xqaVXSO0lKDWZWgauGrGFJejdJw+b3I+JntY7HbLJy1ZCZWc65RGBmlnOZtRFI+hJJ74juiHh2hfUi6dXwcpJ+5W+P5Hb+fVq4cGEsXbp0nKM1M2tsd999d09EtFdal2Vj8bUk3QzH6rt9AckYJ8eRdGn7HM/s2vYMS5cuZc2aNeMUoplZPkgafUf7iMyqhtLGuU372ORC4CuR+DnJkAFHZhWPmZlVVss2gkXsPc5JF2OMoZIOlbtG0ppisTghwZmZ5UUtE4EqLKvYhSkiro6IjojoaG+vWMVlZmYHqZaJoIu9B7xazJ5BrczMbILUMhHcCrw1HZDs+cDWdKwXMzObQJklAkk3kAzgdYKSRw++U9Klki5NN7kN6CQZ8Or/kjzAwsyqtHJVgdWFvceqW13oYeWqg30MxOQ+bi2P3ejnnGWvoYsi4siIaI2IxRHxxYhYGREr0/UREe+JiBUR8ZyIcJ/QcVLLP9o8qtXnfcriOVx2/b0jx15d6OGy6+/llMVzGvK4tTx2o59z3Q0x0dHREfVyH8HKVQVOWTyHs1YsHFm2utDD/V1bufQlB/xcj6oN/6FcefHpnLVi4TPms1Src66l8f68h0rBwFCJ3YMlBobS12DQPzRE/2Cyrn+oxMBgiV91beGqnxR48fEL+dlve3jn7y/j+MNnARAEEUkPjPL/82RZsm7P/J5thh8mutc2o97XWezlxrvWc+bS+fzysU38UccSli2ckTz6sMI+Kx63wjIYfnzunvWjz2X9pj6+/8BTnLJoDvc/sY2XP/sIjl4wHSGaBBIk96um0wiJZF06nawTSrdpktJtkwV7LU+nC919XPeLdbxgxQLuLGzkLS9YyrGHzWQirO3u5at3PsYrTz2KHz709EH9bUm6OyI6Kq5zIsjOeF8gIoLB9CKRXBiSi8Tg0J7p5BXct34zn/nR7zjnhMP4ySPd/OV5J9BxzDzaWpppa2mirbVpz3RL08g/zmQ752plnYD6B0ts3zXAtl2Dyc+dg2zbNTAy/dCTW7nt109x3OEz+e3TvXQcM4+501vpHyzRPxQMpBf1/qES/YN7fk/9FZaX6utf0ibY+156LH/xshMO+H1OBDW0utDDu7+8hmMWTGdtsY/Tj57LnKmtyQW8FHtdFMov5GNNZ2VKmhDGShRtrWXTLc3p+srbd23eyVd/vo6XpN9S33POCk5ZPJeWJtHa0kRrUxMtzaK1WbSMTDfR2pxOp8tamlR1gtpXAnrB8gX09Q+xbecA23ftfQEfvrhvGz2/c2CvC/+ugdI+jy9Ba5PoHwpmtbWwYOYUprQ0jZzXlOamdD4915Ym2tJ1rS3JsiktyXatIy/RVraP1pbh/ez5vB55ejv/cvsjvOKUI/ner5/kwy8/kdOWzNvzrTeNjfJvwuz9bThdS/lHPfytutI2Atas28TffPsB/vCMxXzrni4+9d+fw5nLFux1TJFsXO1xR94zMr1n+/KYhn+3b37e0XztF49z5UWn8/zlC0ZKIKWKJZ5kvlRWYikv9QTpunQZZSWS4ffc/dgmPvqdB3nNaUdxy30b+OSrT+aMY+ZV8dd56O5Zt5mP3fogb+hYzDfvecIlgnpLBKVScPxHvs9gKZg9tYX2WW17/aO3jlwgmkYulFPSdS3Ne6ZHv2f4wtDapLKLhNKLaRO/fXob/+fHa3nZyUdw+4NP8Wdnr2B5+0x2D5bYPTCU/BwssXtwiN0DZdODJXYPlNg1srxs24Eh+iu8r39o3xfJQ9HSpJHk0NqSfkbNexLFnukmdvUPsbbYy+Gz23hq227mz2ilfzDYvmtgv9+y21qamDW1ldnTWpKfU1uYnc7PntrKrKktzJ6W/pzaOrLt8Lr712/lvTeWXZwmoBquVqWvWlY9+pwP/thOBDV066828L4b7uWcE9r5VdfWuvrDqVaplFRNDSeOOwsb+ditD/Ly5xzB9+5/kr942QmceMSspASUVmUNDpUYKCU/B4eCgVL6My357LU+rQ7ba33Z9uXr123sY8PWXSxbOJ3TlsxLLugVLuDDF/tZ6YV8amvzQZ9/o1aHTbbj1vLYjXDOTgQ1srrQw5989W627xrkxkueTymioS8Qw8ep9TenifxWDvlsILf640RQIytXFdiwZSdfuXMdv/zwuRw2a2rDXyDy2FPKrB44EdTQR295gFvue4L7P/6yceuZY8/kb+Vm+7avROCH12esUOxlRftMJ4GMVbrYn7VioUsDZlXwoyozNpwIzMwmKyeCDG3fNcDT23az4rAZtQ7FzGxMTgQZ6iz2AbB8oUsEZjZ5ORFkqLOnF4BjXSIws0nMiSBDhe4+mpvE0fOdCMxs8nIiyFCh2Msx86czpcUfs5lNXr5CZahQ7GW5ewyZ2STnRJCRoVLwWM8OVrS7WsjMJjcngox0bd5B/1DJ9xCY2aTnRJCRQjHpMeR7CMxssnMiyEih2/cQmFl9cCLISKHYy4IZU5g3Y0qtQzEz2ycngox0FvtY7oZiM6sDTgQZ8WBzZlYvnAgysLmvn419/U4EZlYXnAgyMDzGkHsMmVk9cCLIwHCPIZcIzKweOBFkoNDTy5TmJhbPm17rUMzM9suJIAOF7j6WLpxOc5MfT2lmk58TQQY63WPIzOqIE8E46x8ssW7TDicCM6sbTgTj7PFNfQyVwj2GzKxuOBGMs0LRPYbMrL44EYyz4VFHly10icDM6oMTwTgrdPdx+Ow2Zk1trXUoZmZVcSIYZx5jyMzqjRPBOIoIJwIzqztOBOOop7ef7bsG/ZxiM6srmSYCSedLekTSWklXVFg/R9K/S/qVpAclvSPLeLI23FC83CUCM6sjmSUCSc3AVcAFwEnARZJOGrXZe4CHIuJU4GzgXyTV7SO99jyn2InAzOpHliWCM4G1EdEZEf3AjcCFo7YJYJYkATOBTcBghjFlqtDdx7TWZo6cPbXWoZiZVS3LRLAIWF8235UuK3clcCKwAfg1cHlElEbvSNIlktZIWlMsFrOK95AVir0sb59BkwebM7M6kmUiqHQ1jFHz5wH3AUcBpwFXSpr9jDdFXB0RHRHR0d7ePt5xjpvOHvcYMrP6k2Ui6AKWlM0vJvnmX+4dwM2RWAs8Cjwrw5gys2tgiK7NO/3AejOrO1kmgruA4yQtSxuA3wjcOmqbx4FzASQdDpwAdGYYU2Ye7ekjwmMMmVn9aclqxxExKOky4HagGfhSRDwo6dJ0/Urg74BrJf2apCrpQxHRk1VMWRrpMeREYGZ1JrNEABARtwG3jVq2smx6A/CyLGOYKIXuPiQPNmdm9cd3Fo+Tzp5eFs2dxrQpzbUOxczsgDgRjJOk66irhcys/jgRjINSKSh093mMITOrS04E4+CpbbvYOTDkhmIzq0tOBOPAPYbMrJ45EYyDzuHnFPuB9WZWh5wIxkGh2MusthbaZ7bVOhQzswPmRDAOCsVelh82k2QQVTOz+uJEMA7cY8jM6pkTwSHq3T3IU9t2uaHYzOqWE8EhenS4odiJwMzqlBPBIdrTddRVQ2ZWn5wIDlGh2Etzkzh6wfRah2JmdlCcCA5RodjL0fOn09biwebMrD45ERwi9xgys3rnRHAIhkrBoxv73FBsZnXNieAQPLF5J/2DJT+n2MzqmhPBIfBgc2bWCJwIDoETgZk1AieCQ1Ao9jJ/xhTmzZhS61DMzA6aE8EhKBTdY8jM6p8TwSHoLPayfKGrhcysvjkRHKQtO/rp6e33w2jMrO45ERykggebM7MG4URwkNxjyMwahRPBQeos9jGluYnF86bVOhQzs0PiRHCQCsVejlkwnZZmf4RmVt98FTtIhWKvq4XMrCE4ERyEgaESj2/c4R5DZtYQnAgOwrqNOxgshUsEZtYQnAgOQqd7DJlZA3EiOAjD9xB4+GkzawROBAehUOzlsFltzJraWutQzMwOmRPBQXCPITNrJFUlAknfkvQKSblPHBFBobvXPYbMrGFUe2H/HHAx8DtJn5L0rAxjmtQ29vWzbdegSwRm1jCqSgQR8aOIeBNwBvAY8ENJqyW9Q1KuKsoL3UmPoeVOBGbWIKqu6pG0AHg78C7gXuDfSBLDD/fxnvMlPSJpraQrxtjmbEn3SXpQ0qoDir4G9ow66qohM2sMLdVsJOlm4FnAV4FXRcST6aqbJK0Z4z3NwFXAfwO6gLsk3RoRD5VtMxf4LHB+RDwu6bCDPpMJUij2MrW1iaPmeLA5M2sMVSUC4MqI+I9KKyKiY4z3nAmsjYhOAEk3AhcCD5VtczFwc0Q8nu6ru8p4aqaQPpWsqUm1DsXMbFxUWzV0YvrtHQBJ8yT92X7eswhYXzbflS4rdzwwT9JPJd0t6a2VdiTpEklrJK0pFotVhpyNzmIfKw5z+4CZNY5qE8G7I2LL8ExEbAbevZ/3VPrKHKPmW4DnAq8AzgM+Kun4Z7wp4uqI6IiIjvb29ipDHn+7BoZYv3mH2wfMrKFUWzXUJEkRETBS/z9lP+/pApaUzS8GNlTYpici+oA+ST8DTgV+W2VcE+qxjX1EuMeQmTWWaksEtwNfl3SupJcCNwA/2M977gKOk7RM0hTgjcCto7b5DvAiSS2SpgPPAx6uPvyJVeh2jyEzazzVlgg+BPwJ8KckVT53AF/Y1xsiYlDSZSRJpBn4UkQ8KOnSdP3KiHhY0g+A+4ES8IWIeODgTiV7w88pXr7QJQIzaxxVJYKIKJHcXfy5A9l5RNwG3DZq2cpR8/8E/NOB7LdWOou9LJo7jWlTmmsdipnZuKn2PoLjgP8JnARMHV4eEcszimtSKrjHkJk1oGrbCK4hKQ0MAucAXyG5uSw3IiK9h8DtA2bWWKpNBNMi4seAImJdRHwCeGl2YU0+T23bxY7+IZcIzKzhVNtYvCsdgvp3aQPwE8CkHw5iPLnHkJk1qmpLBO8HpgPvI7kB7M3A2zKKaVLq7El6DB3rewjMrMHst0SQ3jz2RxHxV0Av8I7Mo5qECt29zGproX1WW61DMTMbV/stEUTEEPBcSbkeZa1Q7GN5+wxy/jGYWQOqto3gXuA7kr4B9A0vjIibM4lqEioUe3nB8gW1DsPMbNxVmwjmAxvZu6dQALlIBH27B3ly6y73GDKzhlTtncW5bBcY9miPewyZWeOq9s7ia3jmENJExB+Pe0ST0PAYQ35gvZk1omqrhr5bNj0VeC3PHFK6YRW6e2kSHL1geq1DMTMbd9VWDX2rfF7SDcCPMoloEioU+zh6/nTaWjzYnJk1nmpvKBvtOODo8QxkMisUe10tZGYNq9o2gu3s3UbwFMkzChreUCl4tKePFx9fu0dkmpllqdqqoVlZBzJZbdiyk92DJfcYMrOGVVXVkKTXSppTNj9X0msyi2oSWTv8VDJXDZlZg6q2jeDjEbF1eCYitgAfzySiSabQ7a6jZtbYqk0ElbartutpXSsU+5g3vZX5M6bUOhQzs0xUmwjWSPpXSSskLZf0aeDuLAObLDrdY8jMGly1ieC9QD9wE/B1YCfwnqyCmkwKxT4nAjNraNX2GuoDrsg4lkln644Benp3s9w9hsysgVXba+iHkuaWzc+TdHtmUU0ShR43FJtZ46u2amhh2lMIgIjYTA6eWTzSY8jDT5tZA6s2EZQkjQwpIWkpFUYjbTSdPX20Nosl86bVOhQzs8xU2wX0w8B/SlqVzr8YuCSbkCaPQncvSxfMoKX5YIdkMjOb/KptLP6BpA6Si/99wHdIeg41tEKxl2NdLWRmDa7aQefeBVwOLCZJBM8H7mTvR1c2lIGhEus27uC8k4+odShmZpmqts7jcuD3gHURcQ5wOlDMLKpJ4PFNOxgshXsMmVnDqzYR7IqIXQCS2iLiN8AJ2YVVe53F9DnFrhoyswZXbWNxV3ofwS3ADyVtpsEfVVkYGXXUN5OZWWOrtrH4tenkJyT9BJgD/CCzqCaBQncv7bPamD21tdahmJll6oBHEI2IVfvfqv4lj6d0acDMGp87yFcQER5szsxyw4mggk19/WzdOeBEYGa54ERQQcE9hswsRzJNBJLOl/SIpLWSxhzGWtLvSRqS9Los46nWSI+hhW4jMLPGl1kikNQMXAVcAJwEXCTppDG2+1/ApBnWutDdS1tLE4vmerA5M2t8WZYIzgTWRkRnRPQDNwIXVtjuvcC3gO4MYzkghWIvy9tn0tSkWodiZpa5LBPBImB92XxXumyEpEXAa4GVGcZxwDp7+tx11MxyI8tEUOnr9OhnGHwG+FBEDO1zR9IlktZIWlMsZjvE0a6BIdZv2uEeQ2aWGwd8Q9kB6AKWlM0v5pnDUnQAN0oCWAi8XNJgRNxSvlFEXA1cDdDR0ZHpA3HWbdxBKTy0hJnlR5aJ4C7gOEnLgCeANwIXl28QEcuGpyVdC3x3dBKYaMM9hlwiMLO8yCwRRMSgpMtIegM1A1+KiAclXZqun1TtAsOGn1PsEoGZ5UWWJQIi4jbgtlHLKiaAiHh7lrFUq7Onj0VzpzF9SqYfjZnZpOE7i0dJuo66NGBm+eFEUCYiKHT3un3AzHLFiaDM09t209c/5HsIzCxXnAjKuMeQmeWRE0GZzuFE4FFHzSxHnAjKFIp9zGxr4bBZbbUOxcxswjgRlBl+PGV6p7OZWS44EZQpdCejjpqZ5YkTQWpH/yAbtu5yjyEzyx0nglTn8OMpXSIws5xxIkgV3GPIzHLKiSBVKPbRJDhmwfRah2JmNqGcCFKFYi9L5k+nraW51qGYmU0oJ4KUxxgys7xyIgBKpeBRP6fYzHLKiQB4YstOdg+WXCIws1xyIsA9hsws35wISHoMASxf6KohM8sfJwKSEsHc6a3MnzGl1qGYmU04JwKS4adXtM/0YHNmlktOBCRVQ+4xZGZ5lftEsHXnAMXtu91jyMxyK/eJYPipZB5+2szyKveJoDAy6qirhswsn3KfCDqLvbQ2iyXzPdicmeVT7hNBodjLMQtm0Nqc+4/CzHIq91c/9xgys7zLdSIYGCqxbmOfG4rNLNdynQjWb9rBwFC466iZ5VquE0GnewyZmeU7ERR8D4GZmRNB+6w25kxrrXUoZmY1k/NE0Oehp80s93KeCHr9MBozy73cJoJNff1s2THgHkNmlnu5TQQjj6d0jyEzy7n8JoLu4UTgEoGZ5VumiUDS+ZIekbRW0hUV1r9J0v3pa7WkU7OMp1yh2EtbSxOL5k6bqEOamU1KmSUCSc3AVcAFwEnARZJOGrXZo8BLIuIU4O+Aq7OKZ7RCsY9lC2fQ1OTHU5pZvmVZIjgTWBsRnRHRD9wIXFi+QUSsjojN6ezPgcUZxrOXTvcYMjMDsk0Ei4D1ZfNd6bKxvBP4fqUVki6RtEbSmmKxeMiB7R4c4vFNO9w+YGZGtomgUp1LVNxQOockEXyo0vqIuDoiOiKio729/ZADW7dxB6VwjyEzM4CWDPfdBSwpm18MbBi9kaRTgC8AF0TExgzjGeEeQ2Zme2RZIrgLOE7SMklTgDcCt5ZvIOlo4GbgLRHx2wxj2cvwPQTLPLyEmVl2JYKIGJR0GXA70Ax8KSIelHRpun4l8DFgAfBZSQCDEdGRVUzDOot9HDVnKjPasiwQmZnVh0yvhBFxG3DbqGUry6bfBbwryxgq8RhDZmZ75O7O4ohIn1PsRGBmBjlMBN3bd9O7e5Dl7jFkZgbkMBG4x5CZ2d7ylwh6hp9T7ERgZgZ5TATdvcyY0szhs9tqHYqZ2aSQv0SQ9hhKu6uameVe7hJBp59TbGa2l1wlgh39gzyxZafbB8zMyuQqETw63FDsm8nMzEbkKhEUiu4xZGY2Wr4SQXcvTYJjFkyvdShmZpNGvhJBsZfF86YztbW51qGYmU0aOUsEfX4YjZnZKA2fCFauKrC60EOpFDza08uK9pmsLvSwclWh1qGZmU0KDZ8ITlk8h8uuv5fv3r+BXQMlEFx2/b2csnhOrUMzM5sUGj4RnLViIVdefDofvuUBAG66az1XXnw6Z61YWOPIzMwmh4ZPBJAkg/NOPhyAN3QscRIwMyuTi0SwutDDf/ymyPteeiw33/sEqws9tQ7JzGzSaPhEsLrQw2XX38uVF5/OX7zsBK68+HQuu/5eJwMzs1TDJ4L7u7bu1SYw3GZwf9fWGkdmZjY5KCJqHcMB6ejoiDVr1tQ6DDOzuiLp7ojoqLSu4UsEZma2b04EZmY550RgZpZzTgRmZjnnRGBmlnN112tIUhFYd5BvXwjk7QYCn3M++Jzz4VDO+ZiIaK+0ou4SwaGQtGas7lONyuecDz7nfMjqnF01ZGaWc04EZmY5l7dEcHWtA6gBn3M++JzzIZNzzlUbgZmZPVPeSgRmZjaKE4GZWc7lJhFIOl/SI5LWSrqi1vFkTdISST+R9LCkByVdXuuYJoKkZkn3SvpurWOZKJLmSvqmpN+kv+8X1DqmLEn68/Rv+gFJN0iaWuuYsiDpS5K6JT1Qtmy+pB9K+l36c954HCsXiUBSM3AVcAFwEnCRpJNqG1XmBoEPRMSJwPOB9+TgnAEuBx6udRAT7N+AH0TEs4BTaeDzl7QIeB/QERHPBpqBN9Y2qsxcC5w/atkVwI8j4jjgx+n8IctFIgDOBNZGRGdE9AM3AhfWOKZMRcSTEXFPOr2d5OKwqLZRZUvSYuAVwBdqHctEkTQbeDHwRYCI6I+ILTUNKnstwDRJLcB0YEON48lERPwM2DRq8YXAl9PpLwOvGY9j5SURLALWl8130eAXxXKSlgKnA7+ocShZ+wzwQaBU4zgm0nKgCFyTVol9QdKMWgeVlYh4Avhn4HHgSWBrRNxR26gm1OER8SQkX/aAw8Zjp3lJBKqwLBf9ZiXNBL4FvD8ittU6nqxIeiXQHRF31zqWCdYCnAF8LiJOB/oYp+qCySitE78QWAYcBcyQ9ObaRlX/8pIIuoAlZfOLadDiZDlJrSRJ4LqIuLnW8WTshcCrJT1GUvX3Uklfq21IE6IL6IqI4dLeN0kSQ6P6A+DRiChGxABwM3BWjWOaSE9LOhIg/dk9HjvNSyK4CzhO0jJJU0gal26tcUyZkiSSeuOHI+Jfax1P1iLiryNicUQsJfn9/kdENPw3xYh4Clgv6YR00bnAQzUMKWuPA8+XND39Gz+XBm4cr+BW4G3p9NuA74zHTlvGYyeTXUQMSroMuJ2kl8GXIuLBGoeVtRcCbwF+Lem+dNnfRMRttQvJMvJe4Lr0S04n8I4ax5OZiPiFpG8C95D0jLuXBh1qQtINwNnAQkldwMeBTwFfl/ROkqT4+nE5loeYMDPLt7xUDZmZ2RicCMzMcs6JwMws55wIzMxyzonAzCznnAjMJpCks/M0MqrVBycCM7OccyIwq0DSmyX9UtJ9kj6fPuegV9K/SLpH0o8ltafbnibp55Lul/Tt4THiJR0r6UeSfpW+Z0W6+5llzw+4Lr1D1qxmnAjMRpF0IvAG4IURcRowBLwJmAHcExFnAKtI7vQE+ArwoYg4Bfh12fLrgKsi4lSS8XCeTJefDryf5NkYy0nuAjermVwMMWF2gM4FngvclX5Zn0YyuFcJuCnd5mvAzZLmAHMjYlW6/MvANyTNAhZFxLcBImIXQLq/X0ZEVzp/H7AU+M/Mz8psDE4EZs8k4MsR8dd7LZQ+Omq7fY3Psq/qnt1l00P4/9BqzFVDZs/0Y+B1kg6DkefEHkPy//K6dJuLgf+MiK3AZkkvSpe/BViVPvuhS9Jr0n20SZo+kSdhVi1/EzEbJSIekvQR4A5JTcAA8B6Sh76cLOluYCtJOwIkwwGvTC/05aN/vgX4vKRPpvsYl5EizcabRx81q5Kk3oiYWes4zMabq4bMzHLOJQIzs5xzicDMLOecCMzMcs6JwMws55wIzMxyzonAzCzn/j8SBXlL6bdqngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [val_acc]+ metrics1+metrics2\n",
    "plt.plot(accuracies,'-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs No of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a7730-73f4-4455-b68b-ccae3c7c2c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
